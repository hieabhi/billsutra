import mongoose from 'mongoose';
import dotenv from 'dotenv';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { dirname } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

dotenv.config({ path: path.join(__dirname, '..', '.env') });

const MONGODB_URI = process.env.MONGODB_URI;
const BACKUP_DIR = path.join(__dirname, '..', 'backups');

/**
 * Automated Backup System
 * CRITICAL: Run this daily to prevent data loss
 */

const createBackup = async () => {
  console.log('\nüíæ MongoDB Backup Utility\n');
  console.log('='.repeat(60));

  if (!MONGODB_URI) {
    console.log('‚ùå ERROR: MONGODB_URI not configured');
    process.exit(1);
  }

  try {
    // Connect to MongoDB
    console.log('üì° Connecting to MongoDB...');
    await mongoose.connect(MONGODB_URI, {
      serverSelectionTimeoutMS: 10000,
    });
    console.log('‚úÖ Connected');

    // Create backup directory with timestamp
    const timestamp = new Date().toISOString().replace(/:/g, '-').split('.')[0];
    const backupPath = path.join(BACKUP_DIR, `backup_${timestamp}`);
    
    if (!fs.existsSync(backupPath)) {
      fs.mkdirSync(backupPath, { recursive: true });
    }

    const db = mongoose.connection.db;
    const collections = await db.listCollections().toArray();

    console.log(`\nüì¶ Backing up ${collections.length} collections...`);

    let totalDocs = 0;

    for (const collectionInfo of collections) {
      const collectionName = collectionInfo.name;
      const collection = db.collection(collectionName);
      
      // Get all documents
      const documents = await collection.find({}).toArray();
      
      // Save to JSON file
      const filename = path.join(backupPath, `${collectionName}.json`);
      fs.writeFileSync(filename, JSON.stringify(documents, null, 2), 'utf8');
      
      console.log(`   ‚úÖ ${collectionName}: ${documents.length} documents`);
      totalDocs += documents.length;
    }

    // Create backup metadata
    const metadata = {
      timestamp: new Date().toISOString(),
      database: db.databaseName,
      collections: collections.length,
      totalDocuments: totalDocs,
      mongodbUri: MONGODB_URI.replace(/\/\/([^:]+):([^@]+)@/, '//$1:****@'),
    };

    fs.writeFileSync(
      path.join(backupPath, '_metadata.json'),
      JSON.stringify(metadata, null, 2),
      'utf8'
    );

    console.log('\n' + '='.repeat(60));
    console.log('‚úÖ Backup Complete!');
    console.log('='.repeat(60));
    console.log(`üìÅ Location: ${backupPath}`);
    console.log(`üìä Collections: ${collections.length}`);
    console.log(`üìÑ Documents: ${totalDocs}`);
    console.log(`‚è∞ Timestamp: ${timestamp}`);
    console.log('='.repeat(60));

    // Cleanup old backups (keep last 7 days)
    cleanupOldBackups();

  } catch (error) {
    console.error('\n‚ùå Backup failed:', error.message);
    process.exit(1);
  } finally {
    await mongoose.connection.close();
    console.log('\nüîå Disconnected from MongoDB\n');
  }
};

const cleanupOldBackups = () => {
  if (!fs.existsSync(BACKUP_DIR)) return;

  const backups = fs.readdirSync(BACKUP_DIR)
    .filter(name => name.startsWith('backup_'))
    .map(name => ({
      name,
      path: path.join(BACKUP_DIR, name),
      time: fs.statSync(path.join(BACKUP_DIR, name)).mtime.getTime()
    }))
    .sort((a, b) => b.time - a.time);

  // Keep only last 7 backups
  if (backups.length > 7) {
    console.log('\nüßπ Cleaning up old backups...');
    const toDelete = backups.slice(7);
    
    toDelete.forEach(backup => {
      fs.rmSync(backup.path, { recursive: true, force: true });
      console.log(`   üóëÔ∏è  Deleted: ${backup.name}`);
    });
    
    console.log(`‚úÖ Kept ${7} most recent backups`);
  }
};

// Restore from backup
export const restoreBackup = async (backupName) => {
  console.log(`\n‚ôªÔ∏è  Restoring from backup: ${backupName}\n`);
  console.log('='.repeat(60));

  const backupPath = path.join(BACKUP_DIR, backupName);

  if (!fs.existsSync(backupPath)) {
    console.log(`‚ùå Backup not found: ${backupName}`);
    process.exit(1);
  }

  try {
    await mongoose.connect(MONGODB_URI);
    console.log('‚úÖ Connected to MongoDB');

    const files = fs.readdirSync(backupPath).filter(f => f.endsWith('.json') && f !== '_metadata.json');

    console.log(`\nüì¶ Restoring ${files.length} collections...`);

    const db = mongoose.connection.db;

    for (const file of files) {
      const collectionName = file.replace('.json', '');
      const filepath = path.join(backupPath, file);
      
      const data = JSON.parse(fs.readFileSync(filepath, 'utf8'));
      
      if (data.length === 0) {
        console.log(`   ‚è≠Ô∏è  ${collectionName}: empty, skipping`);
        continue;
      }

      // Drop existing collection
      try {
        await db.collection(collectionName).drop();
      } catch (e) {
        // Collection might not exist
      }

      // Insert documents
      await db.collection(collectionName).insertMany(data);
      console.log(`   ‚úÖ ${collectionName}: ${data.length} documents restored`);
    }

    console.log('\n‚úÖ Restore complete!');

  } catch (error) {
    console.error('\n‚ùå Restore failed:', error.message);
    process.exit(1);
  } finally {
    await mongoose.connection.close();
    console.log('\nüîå Disconnected from MongoDB\n');
  }
};

// If run directly
if (import.meta.url === `file://${process.argv[1]}`) {
  createBackup();
}

export default createBackup;
